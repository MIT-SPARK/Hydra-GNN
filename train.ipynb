{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra_gnn.utils import PROJECT_DIR, MP3D_BENCHMARK_DIR\n",
    "from hydra_gnn.mp3d_utils import read_mp3d_split\n",
    "from hydra_gnn.mp3d_dataset import Hydra_mp3d_dataset\n",
    "from hydra_gnn.base_training_job import BaseTrainingJob\n",
    "import os\n",
    "import pickle\n",
    "import yaml\n",
    "from statistics import mean, stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "import datetime\n",
    "t = datetime.datetime.now()\n",
    "output_name = t.strftime('%m%d%H%M')\n",
    "\n",
    "config = dict()\n",
    "config['data'] = {\n",
    "    'file_path':\"output/preprocessed_mp3d/htree_gt60.pkl\",\n",
    "    'type': 'heterogeneous'\n",
    "}\n",
    "config['run_control'] = {\n",
    "    'num_runs': 1,\n",
    "    'early_stop_window': 300\n",
    "}\n",
    "config['network'] = {\n",
    "    'conv_block': 'GAT_edge',\n",
    "    'dropout': 0.4,\n",
    "    'GAT_hidden_dims': [32, 32],\n",
    "    'GAT_heads': [1, 1, 1],\n",
    "    'GAT_concats': [True, True, False]\n",
    "}\n",
    "config['optimization'] = {\n",
    "    'lr': 0.001,\n",
    "    'num_epochs': 800,\n",
    "    'weight_decay': 0.0,\n",
    "    'batch_size': 2048\n",
    "}\n",
    "config['logger'] = {\n",
    "    'output_dir': \"output/log_test/\" + output_name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(PROJECT_DIR, config['data']['file_path'])\n",
    "output_dir = os.path.join(PROJECT_DIR, config['logger']['output_dir'])\n",
    "num_runs = config['run_control']['num_runs']\n",
    "network_type = config['data']['type']\n",
    "early_stop_window = config['run_control']['early_stop_window']\n",
    "network_params = config['network']\n",
    "optimization_params = config['optimization']\n",
    "\n",
    "print(network_type)\n",
    "print(dataset_path)\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dict = read_mp3d_split(MP3D_BENCHMARK_DIR)\n",
    "with open(dataset_path, 'rb') as input_file:\n",
    "    data_list = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_data = data_list[0].get_torch_data()\n",
    "for node_type in torch_data.x_dict:\n",
    "    if 'y' in torch_data[node_type]:\n",
    "        print(node_type, torch_data[node_type].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {'train': Hydra_mp3d_dataset('train', remove_short_trajectories=True),\n",
    "                'val': Hydra_mp3d_dataset('val'),\n",
    "                'test': Hydra_mp3d_dataset('test')}\n",
    "\n",
    "if config['network']['conv_block'] == 'GAT_edge':\n",
    "    [data.compute_relative_pos() for data in data_list]\n",
    "if network_type[:11] == 'homogeneous':\n",
    "    [data.to_homogeneous() for data in data_list]\n",
    "# [data.remove_last_features(300) for data in data_list]\n",
    "\n",
    "for data in data_list:\n",
    "    if data.get_data_info()['scene_id'] in split_dict['scenes_train']:\n",
    "        dataset_dict['train'].add_data(data)\n",
    "    else:\n",
    "        if data.get_data_info()['trajectory_id'] in ['0', '1']:\n",
    "            dataset_dict['val'].add_data(data)\n",
    "        elif data.get_data_info()['trajectory_id'] in ['2', '3', '4']:\n",
    "            dataset_dict['test'].add_data(data)\n",
    "        else:\n",
    "            raise RuntimeError(f\"Found invalid trajectory id in input data file {dataset_path}\")\n",
    "print(f\"  training: {dataset_dict['train'].num_scenes()} scenes {len(dataset_dict['train'])} graphs\\n\"\n",
    "      f\"  validation: {dataset_dict['val'].num_scenes()} scenes {len(dataset_dict['val'])} graphs\\n\"\n",
    "      f\"  test: {dataset_dict['test'].num_scenes()} scenes {len(dataset_dict['test'])} graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_output_dir = os.path.join(PROJECT_DIR, config['logger']['output_dir'])\n",
    "assert not os.path.exists(experiment_output_dir), \"Output directory exists\"\n",
    "os.mkdir(experiment_output_dir)\n",
    "\n",
    "test_accuracy_list = []\n",
    "val_accuracy_list = []\n",
    "training_time_list = []\n",
    "training_epoch_list = []\n",
    "test_time_list = []\n",
    "for j in range(config['run_control']['num_runs']):\n",
    "    train_job = BaseTrainingJob(dataset_dict=dataset_dict, \n",
    "                                network_params=config['network'])\n",
    "    model, best_acc, info = train_job.train(\n",
    "        experiment_output_dir + '/' + str(j), \n",
    "        optimization_params=config['optimization'],\n",
    "        early_stop_window=config['run_control']['early_stop_window'], \n",
    "        verbose=True)\n",
    "\n",
    "    val_accuracy_list.append(best_acc[0] * 100)\n",
    "    test_accuracy_list.append(best_acc[1] * 100)\n",
    "    training_time_list.append(info['training_time'])\n",
    "    training_epoch_list.append(info['num_epochs'])\n",
    "    test_time_list.append(info['test_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['run_control']['num_runs'] > 2:\n",
    "    print(f\"Validation accuracy: {mean(val_accuracy_list)} +/- {stdev(val_accuracy_list)}\")\n",
    "    print(f\"Test accuracy: {mean(test_accuracy_list)} +/- {stdev(test_accuracy_list)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save last model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model hyper-parameters\n",
    "network_params = train_job.get_network_params()\n",
    "graph_type, network_type = train_job.train_job_type().split(' ')\n",
    "with open(os.path.join(experiment_output_dir, 'model.yaml'), 'w') as output_file:\n",
    "    yaml.dump({'graph_type': graph_type,\n",
    "               'network_type': network_type,\n",
    "               'network_params': network_params}, \n",
    "              output_file, default_flow_style=False)\n",
    "\n",
    "# save last model weights\n",
    "model_weights_path = os.path.join(experiment_output_dir + '/' + str(j), 'model_weights.pth')\n",
    "torch.save(model.state_dict(), model_weights_path)\n",
    "print(\"model params saved to:\", experiment_output_dir + '/' + str(j))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_hydra_gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "967e0c2ffd26b9faa12181abf2fe57108176e775fc50d31e459720dbf04edf24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
