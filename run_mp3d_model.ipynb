{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark_dsg as dsg\n",
    "from spark_dsg.mp3d import load_mp3d_info\n",
    "from hydra_gnn.mp3d_dataset import Hydra_mp3d_data, Hydra_mp3d_htree_data\n",
    "from hydra_gnn.models import HomogeneousNetwork, HeterogeneousNetwork, HomogeneousNeuralTreeNetwork, HeterogeneousNeuralTreeNetwork\n",
    "from hydra_gnn.preprocess_dsgs import dsg_node_converter, hydra_object_feature_converter\n",
    "from hydra_gnn.utils import COLORMAP_DATA_PATH, WORD2VEC_MODEL_PATH\n",
    "import gensim\n",
    "import torch\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model files\n",
    "model_dir = \"./output/pretrained_models/data_gt60_model_noSemantics\"\n",
    "with_word2vec = False\n",
    "hyper_param_path = f\"{model_dir}/model.yaml\"\n",
    "model_weight_path = f\"{model_dir}/model_weights.pth\"\n",
    "\n",
    "# example dsg\n",
    "example_dsg_path = \"./tests/test_data/17DRP5sb8fy_0_gt_partial_dsg_1414.json\"\n",
    "example_house_file_path = \"./tests/test_data/17DRP5sb8fy.house\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# room labels filtering function -- keep rooms that have more than 1 children (objects) or have siblings (rooms)\n",
    "room_removal_func = lambda room: not (len(room.children()) > 1 or room.has_siblings())\n",
    "\n",
    "# dsg construction/conversion params\n",
    "threshold_near=1.5\n",
    "max_near=2.0\n",
    "max_on=0.2\n",
    "object_synonyms=[]\n",
    "room_synonyms=[('a', 't'), ('z', 'Z', 'x', 'p', '\\x15')]\n",
    "min_iou = 0.6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(hyper_param_path, 'r') as input_file:\n",
    "    model_param = yaml.safe_load(input_file)\n",
    "\n",
    "network_type, graph_type = model_param['network_type'], model_param['graph_type']\n",
    "print(f\"network type: {network_type}\")\n",
    "print(f\"graph type: {graph_type}\")\n",
    "print(f\"model hyper params: {model_param['network_params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model and load weights\n",
    "if model_param['graph_type'] == 'homogeneous':\n",
    "    if network_type == 'baseline':\n",
    "        model = HomogeneousNetwork(**model_param['network_params'])\n",
    "    else:\n",
    "        model = HomogeneousNeuralTreeNetwork(**model_param['network_params'])\n",
    "else:\n",
    "    if network_type == 'baseline':\n",
    "        model = HeterogeneousNetwork(**model_param['network_params'])\n",
    "    else:\n",
    "        model = HeterogeneousNeuralTreeNetwork(**model_param['network_params'])\n",
    "    \n",
    "model.load_state_dict(torch.load(model_weight_path))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsg node attributes to PyG node feature converter\n",
    "colormap_data = pd.read_csv(COLORMAP_DATA_PATH, delimiter=',')\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(WORD2VEC_MODEL_PATH, binary=True)\n",
    "object_feature_converter=hydra_object_feature_converter(colormap_data, word2vec_model)\n",
    "room_feature_converter = lambda i: np.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load example graph for testing\n",
    "if model_param['network_type'] == 'baseline':\n",
    "    data = Hydra_mp3d_data(scene_id=0, trajectory_id=0, num_frames=0, file_path=example_dsg_path)\n",
    "else:\n",
    "    data = Hydra_mp3d_htree_data(scene_id=0, trajectory_id=0, num_frames=0, file_path=example_dsg_path)\n",
    "    \n",
    "# skip dsg without room node or without object node\n",
    "if data.get_room_object_dsg().num_nodes() == 0 or \\\n",
    "    data.get_room_object_dsg().get_layer(dsg.DsgLayers.OBJECTS).num_nodes() == 0 or \\\n",
    "        data.get_room_object_dsg().get_layer(dsg.DsgLayers.ROOMS).num_nodes() == 0:\n",
    "    raise RuntimeError(\"Input dsg does not satisfy minimum node number requirement.\")\n",
    "\n",
    "# parepare torch data\n",
    "data.add_dsg_room_labels(load_mp3d_info(example_house_file_path), angle_deg=-90, room_removal_func=room_removal_func, \\\n",
    "    min_iou_threshold=min_iou, repartition_rooms=True)\n",
    "if data.get_room_object_dsg().get_layer(dsg.DsgLayers.OBJECTS).num_nodes() == 0:\n",
    "    raise RuntimeError(\"Input dsg does not contain any object node after room repartitioning.\")\n",
    "\n",
    "data.add_object_edges(threshold_near=threshold_near, max_near=max_near, max_on=max_on)\n",
    "data.compute_torch_data(use_heterogeneous=True,\n",
    "                        node_converter=dsg_node_converter(object_feature_converter, room_feature_converter),\n",
    "                        object_synonyms=object_synonyms, \n",
    "                        room_synonyms=room_synonyms)\n",
    "data.clear_dsg()    # remove hydra dsg \n",
    "\n",
    "if model_param['network_params']['conv_block'] == 'GAT_edge':\n",
    "    data.compute_relative_pos()\n",
    "if graph_type == 'homogeneous':\n",
    "    data.to_homogeneous()\n",
    "if not with_word2vec:\n",
    "    data.remove_last_features(300)\n",
    "\n",
    "# get PyG data\n",
    "data = data.get_torch_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass data through pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass prepared data through model - this will run on cuda if gpu is available\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(data.to(device)).argmax(dim=1)    \n",
    "    if graph_type == 'homogeneous':\n",
    "        label = data.y[data.room_mask]\n",
    "    else:\n",
    "        if network_type == 'baseline':\n",
    "            label = data['rooms'].y\n",
    "        else:\n",
    "            label = data['room_virtual'].y\n",
    "    mask = (label != 25)    # ignore label 25, which is the unknown/filtered label\n",
    "    pred = pred[mask]\n",
    "    label = label[mask]\n",
    "print(f\"Predicted room labels: {pred}\")\n",
    "print(f\"Ground truth room labels: {label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_hydra_gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
